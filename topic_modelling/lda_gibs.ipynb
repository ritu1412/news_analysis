{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import codecs\n",
    "import re\n",
    "import json\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(json_file_path):\n",
    "    # Get English stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # Read dataset file\n",
    "    with codecs.open(json_file_path, 'r', 'utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    word2id = {}\n",
    "    id2word = {}\n",
    "    docs = []\n",
    "    currentDocument = []\n",
    "    currentWordId = 0\n",
    "\n",
    "    for document in data:\n",
    "        body_text = document.get(\"summary\", \"\")\n",
    "        if not body_text:\n",
    "            continue\n",
    "        \n",
    "        # Tokenize words using nltk\n",
    "        words = nltk.word_tokenize(body_text)\n",
    "        for word in words:\n",
    "            word = word.lower().strip()\n",
    "            # Word length greater than 1 and does not contain numbers and is not a stopword\n",
    "            if len(word) > 1 and word.isalpha() and word not in stop_words:\n",
    "                if word in word2id:\n",
    "                    currentDocument.append(word2id[word])\n",
    "                else:\n",
    "                    currentDocument.append(currentWordId)\n",
    "                    word2id[word] = currentWordId\n",
    "                    id2word[currentWordId] = word\n",
    "                    currentWordId += 1\n",
    "        docs.append(currentDocument)\n",
    "        currentDocument = []\n",
    "    \n",
    "    return docs, word2id, id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomInitialize():\n",
    "\tfor d, doc in enumerate(docs):\n",
    "\t\tzCurrentDoc = []\n",
    "\t\tfor w in doc:\n",
    "\t\t\tpz = np.divide(np.multiply(ndz[d, :], nzw[:, w]), nz)\n",
    "\t\t\tz = np.random.multinomial(1, pz / pz.sum()).argmax()\n",
    "\t\t\tzCurrentDoc.append(z)\n",
    "\t\t\tndz[d, z] += 1\n",
    "\t\t\tnzw[z, w] += 1\n",
    "\t\t\tnz[z] += 1\n",
    "\t\tZ.append(zCurrentDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbsSampling():\n",
    "\tfor d, doc in enumerate(docs):\n",
    "\t\tfor index, w in enumerate(doc):\n",
    "\t\t\tz = Z[d][index]\n",
    "\t\t\tndz[d, z] -= 1\n",
    "\t\t\tnzw[z, w] -= 1\n",
    "\t\t\tnz[z] -= 1\n",
    "\t\t\tpz = np.divide(np.multiply(ndz[d, :], nzw[:, w]), nz)\n",
    "\t\t\tz = np.random.multinomial(1, pz / pz.sum()).argmax()\n",
    "\t\t\tZ[d][index] = z \n",
    "\t\t\tndz[d, z] += 1\n",
    "\t\t\tnzw[z, w] += 1\n",
    "\t\t\tnz[z] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity():\n",
    "\tnd = np.sum(ndz, 1)\n",
    "\tn = 0\n",
    "\tll = 0.0\n",
    "\tfor d, doc in enumerate(docs):\n",
    "\t\tfor w in doc:\n",
    "\t\t\tll = ll + np.log(((nzw[:, w] / nz) * (ndz[d, :] / nd[d])).sum())\n",
    "\t\t\tn = n + 1\n",
    "\treturn np.exp(ll/(-n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:39:58 Iteration:  0  Completed  Perplexity:  1601.4458812967484\n",
      "23:39:58 Iteration:  1  Completed  Perplexity:  1564.8555620861898\n",
      "23:39:59 Iteration:  2  Completed  Perplexity:  1525.4060103569052\n",
      "23:39:59 Iteration:  3  Completed  Perplexity:  1483.049077948842\n",
      "23:39:59 Iteration:  4  Completed  Perplexity:  1440.6696384791242\n",
      "23:40:00 Iteration:  5  Completed  Perplexity:  1400.1632282464623\n",
      "23:40:00 Iteration:  6  Completed  Perplexity:  1363.7493807685983\n",
      "23:40:00 Iteration:  7  Completed  Perplexity:  1330.5314447940789\n",
      "23:40:01 Iteration:  8  Completed  Perplexity:  1307.2173167075662\n",
      "23:40:01 Iteration:  9  Completed  Perplexity:  1286.9411632313015\n",
      "23:40:02 Iteration:  10  Completed  Perplexity:  1272.0184361807794\n",
      "23:40:02 Iteration:  11  Completed  Perplexity:  1259.5159278123035\n",
      "23:40:02 Iteration:  12  Completed  Perplexity:  1248.9676010688079\n",
      "23:40:03 Iteration:  13  Completed  Perplexity:  1238.830571996407\n",
      "23:40:03 Iteration:  14  Completed  Perplexity:  1228.6396698954939\n",
      "23:40:03 Iteration:  15  Completed  Perplexity:  1220.5374342456162\n",
      "23:40:04 Iteration:  16  Completed  Perplexity:  1211.2498338125872\n",
      "23:40:04 Iteration:  17  Completed  Perplexity:  1203.4129912009107\n",
      "23:40:04 Iteration:  18  Completed  Perplexity:  1199.6415290957984\n",
      "23:40:05 Iteration:  19  Completed  Perplexity:  1194.0035730330274\n",
      "23:40:05 Iteration:  20  Completed  Perplexity:  1187.9777561755882\n",
      "23:40:05 Iteration:  21  Completed  Perplexity:  1184.1411421401913\n",
      "23:40:06 Iteration:  22  Completed  Perplexity:  1180.1601487579553\n",
      "23:40:06 Iteration:  23  Completed  Perplexity:  1173.3961392238891\n",
      "23:40:06 Iteration:  24  Completed  Perplexity:  1169.2855466725734\n",
      "23:40:07 Iteration:  25  Completed  Perplexity:  1166.1820710218763\n",
      "23:40:07 Iteration:  26  Completed  Perplexity:  1161.6655325345837\n",
      "23:40:07 Iteration:  27  Completed  Perplexity:  1161.3493472958778\n",
      "23:40:08 Iteration:  28  Completed  Perplexity:  1159.7763001810495\n",
      "23:40:08 Iteration:  29  Completed  Perplexity:  1160.4384688738353\n",
      "23:40:08 Iteration:  30  Completed  Perplexity:  1157.4947026178684\n",
      "23:40:09 Iteration:  31  Completed  Perplexity:  1156.6001577775437\n",
      "23:40:09 Iteration:  32  Completed  Perplexity:  1155.7922082447822\n",
      "23:40:09 Iteration:  33  Completed  Perplexity:  1156.7516515447198\n",
      "23:40:10 Iteration:  34  Completed  Perplexity:  1155.1411888723292\n",
      "23:40:10 Iteration:  35  Completed  Perplexity:  1153.138704830221\n",
      "23:40:10 Iteration:  36  Completed  Perplexity:  1150.1600826088188\n",
      "23:40:11 Iteration:  37  Completed  Perplexity:  1148.6779757850375\n",
      "23:40:11 Iteration:  38  Completed  Perplexity:  1149.0868793502555\n",
      "23:40:11 Iteration:  39  Completed  Perplexity:  1145.8990957311535\n",
      "23:40:12 Iteration:  40  Completed  Perplexity:  1145.2666727353642\n",
      "23:40:12 Iteration:  41  Completed  Perplexity:  1144.2573750478598\n",
      "23:40:12 Iteration:  42  Completed  Perplexity:  1145.7701289349316\n",
      "23:40:13 Iteration:  43  Completed  Perplexity:  1145.6923040644688\n",
      "23:40:13 Iteration:  44  Completed  Perplexity:  1146.0961230171902\n",
      "23:40:13 Iteration:  45  Completed  Perplexity:  1144.0207101231256\n",
      "23:40:14 Iteration:  46  Completed  Perplexity:  1143.8014284415651\n",
      "23:40:14 Iteration:  47  Completed  Perplexity:  1143.0807821919911\n",
      "23:40:14 Iteration:  48  Completed  Perplexity:  1144.0765983647818\n",
      "23:40:15 Iteration:  49  Completed  Perplexity:  1143.5041276502377\n"
     ]
    }
   ],
   "source": [
    "alpha = 5\n",
    "beta = 0.1\t\n",
    "iterationNum = 50\n",
    "Z = []\n",
    "K = 3\n",
    "docs, word2id, id2word = preprocessing(\"combined_summary.json\")\n",
    "N = len(docs)\n",
    "M = len(word2id)\n",
    "ndz = np.zeros([N, K]) + alpha\n",
    "nzw = np.zeros([K, M]) + beta\n",
    "nz = np.zeros([K]) + M * beta\n",
    "randomInitialize()\n",
    "for i in range(0, iterationNum):\n",
    "\tgibbsSampling()\n",
    "\tprint(time.strftime('%X'), \"Iteration: \", i, \" Completed\", \" Perplexity: \", perplexity())\n",
    " \n",
    "topicwords = []\n",
    "maxTopicWordsNum = 10\n",
    "for z in range(0, K):\n",
    "\tids = nzw[z, :].argsort()\n",
    "\ttopicword = []\n",
    "\tfor j in ids:\n",
    "\t\ttopicword.insert(0, id2word[j])\n",
    "\ttopicwords.append(topicword[0 : min(10, len(topicword))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['seats',\n",
       "  'bjp',\n",
       "  'india',\n",
       "  'israel',\n",
       "  'gaza',\n",
       "  'israeli',\n",
       "  'congress',\n",
       "  'modi',\n",
       "  'nda',\n",
       "  'sabha'],\n",
       " ['china',\n",
       "  'sea',\n",
       "  'philippines',\n",
       "  'south',\n",
       "  'chinese',\n",
       "  'president',\n",
       "  'philippine',\n",
       "  'ukraine',\n",
       "  'military',\n",
       "  'dialogue'],\n",
       " ['minister',\n",
       "  'national',\n",
       "  'president',\n",
       "  'coalition',\n",
       "  'article',\n",
       "  'meeting',\n",
       "  'despite',\n",
       "  'new',\n",
       "  'june',\n",
       "  'including']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topicwords"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
