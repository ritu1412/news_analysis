{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "class FactorModel(nn.Module):\n",
    "    def __init__(self, N: int, K: List[int], d: int):\n",
    "        super(FactorModel, self).__init__()\n",
    "        self.N = N  # Number of questions\n",
    "        self.K = K  # List of number of categorical answers for each question\n",
    "        self.d = d  # Latent dimension\n",
    "        self.W = nn.ModuleList([nn.Linear(d, K[i] - 1, bias=False) for i in range(N)])\n",
    "        self.biases = nn.ParameterList(\n",
    "            [nn.Parameter(torch.randn(K[i] - 1)) for i in range(N)]\n",
    "        )\n",
    "\n",
    "    def forward(self, v: torch.Tensor) -> List[torch.Tensor]:\n",
    "        logits = [self.W[n](v) + self.biases[n] for n in range(self.N)]\n",
    "        # Append zero logits for the last category to each question's logits\n",
    "        logits = [\n",
    "            torch.cat((logit, torch.zeros(logit.size(0), 1).to(logit.device)), dim=1)\n",
    "            for logit in logits\n",
    "        ]\n",
    "        return logits\n",
    "\n",
    "    def predict_proba(self, v: torch.Tensor) -> List[torch.Tensor]:\n",
    "        logits = self.forward(v)  # List of logits for each question\n",
    "        probabilities = [torch.softmax(logit, dim=-1) for logit in logits]\n",
    "        return probabilities\n",
    "\n",
    "\n",
    "def loss_function(\n",
    "    model: FactorModel,\n",
    "    v: torch.Tensor,\n",
    "    answers: torch.Tensor,\n",
    "    lambda1: float,\n",
    "    lambda2: float,\n",
    ") -> torch.Tensor:\n",
    "\n",
    "    criterion = nn.NLLLoss(reduction=\"sum\")\n",
    "    logits = model.forward(v)\n",
    "\n",
    "    total_loss = 0\n",
    "    for n in range(model.N):\n",
    "        log_probs = nn.functional.log_softmax(logits[n], dim=1)\n",
    "        total_loss += criterion(log_probs, answers[:, n])\n",
    "    nll_loss = total_loss.clone()\n",
    "    # L2 Regularization\n",
    "    l2_reg = sum(torch.norm(W.weight, 2) ** 2 for W in model.W)\n",
    "    total_loss += lambda1 * l2_reg\n",
    "    total_loss += lambda2 * torch.norm(v, 2) ** 2\n",
    "    return total_loss, nll_loss\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model: FactorModel,\n",
    "    answers: torch.Tensor,\n",
    "    epochs: int = 1000,\n",
    "    lr: float = 0.01,\n",
    "    lambda1: float = 0.01,\n",
    "    lambda2: float = 0.01,\n",
    ") -> Tuple[FactorModel, torch.Tensor]:\n",
    "\n",
    "    v = torch.randn(len(answers), model.d, requires_grad=True)\n",
    "\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    optimizer = optim.Adam(list(model.parameters()) + [v], lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss, nllloss = loss_function(model, v, answers, lambda1, lambda2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # if epoch % 100 == 0:\n",
    "        # print(f\"Epoch {epoch}, Loss: {loss.item()}, nll_loss: {nllloss.item()}\")\n",
    "    print(\n",
    "        f\"d: {model.d}, Epoch {epoch}, Loss: {loss.item()}, nll_loss: {nllloss.item()}\"\n",
    "    )\n",
    "    return model, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/formated_output_questions.json\") as f:\n",
    "    data = json.load(f)\n",
    "Q = data.values()\n",
    "K = []\n",
    "for q in Q:\n",
    "    choice = q[\"choices\"].values()\n",
    "    K.append(len(choice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the file name that starts with \"QnA\"\n",
    "import os\n",
    "import re\n",
    "\n",
    "file_list = os.listdir(\"data/answers\")\n",
    "file_list.sort()\n",
    "# save the file list to csv file:\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(file_list, columns=[\"file_name\"])\n",
    "df.to_csv(\"data/answers/QnA_file_list.csv\", index=False)\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def extract_answers(file):\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Initialize a list to store the extracted values\n",
    "    answers = []\n",
    "\n",
    "    # Iterate through the JSON objects to extract `post_LLM_answer`\n",
    "    for item in data:\n",
    "\n",
    "        if \"answers\" in item:\n",
    "            # get the value under the key `answers`\n",
    "            answer = item[\"answers\"]\n",
    "            answers.append(list(answer.values()))\n",
    "\n",
    "    # convert the list of extracted values to a numpy array\n",
    "    answers = np.array(answers, dtype=object)\n",
    "    answers = np.where(answers == \"A\", 0, answers)\n",
    "    answers = np.where(answers == \"B\", 1, answers)\n",
    "    answers = np.where(answers == \"C\", 2, answers)\n",
    "    answers = np.where(answers == \"D\", 3, answers)\n",
    "    answers = np.where(answers == \"E\", 4, answers)\n",
    "    answers = answers.astype(int)\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for file in file_list:\n",
    "    answer = extract_answers(\"data/answers/\" + file)\n",
    "    answers.append(answer)\n",
    "answers = np.array(answers)\n",
    "\n",
    "# reshape answers to 600,80\n",
    "answers = answers.reshape(300, 40)\n",
    "answers.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_max = list(answers.max(axis=0) + 1)\n",
    "for i in range(len(ans_max)):\n",
    "    if ans_max[i] > K[i]:\n",
    "        print(i + 1, ans_max[i], K[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "answers = torch.tensor(answers, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(K)  # Number of questions\n",
    "\n",
    "M = answers.shape[0]  # Number of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epo = 20000\n",
    "\n",
    "for d in [3] + list(range(5, 21, 5)):\n",
    "    model = FactorModel(N, K, d)\n",
    "    trained_model, v = train_model(\n",
    "        model, answers, epochs=epo, lr=0.01, lambda1=0.01, lambda2=0.01\n",
    "    )\n",
    "    # Extract the latent vectors v\n",
    "    latent_vectors = v.detach().numpy()\n",
    "    # save the latent vectors to csv file\n",
    "    np.savetxt(\n",
    "        f\"data/latent_vectors_{d}.csv\",\n",
    "        latent_vectors,\n",
    "        delimiter=\",\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "v_2d = tsne.fit_transform(latent_vectors)\n",
    "\n",
    "# Plot the 2D embeddings with the inedx of each point\n",
    "plt.figure(figsize=(10, 8))\n",
    "# split the three topics\n",
    "# concatenate the first 100 and the last 100\n",
    "v_2d_english = v_2d[:100]\n",
    "v_2d_hindi = v_2d[100:200]\n",
    "v_2d_chinease = v_2d[200:300]\n",
    "for index, (x, y) in enumerate(v_2d_english):\n",
    "    plt.scatter(x, y, alpha=0.4, color=\"blue\", s=3, label=\"Russia Ukraine War English\" if index == 0 else \"\")\n",
    "\n",
    "for index, (x, y) in enumerate(v_2d_hindi):\n",
    "    plt.scatter(\n",
    "        x,\n",
    "        y,\n",
    "        alpha=0.4,\n",
    "        color=\"green\",\n",
    "        s=3,\n",
    "        label=\"Russia Ukraine War Hindi\" if index == 0 else \"\",\n",
    "    )\n",
    "\n",
    "for index, (x, y) in enumerate(v_2d_chinease):\n",
    "    plt.scatter(\n",
    "        x,\n",
    "        y,\n",
    "        alpha=0.4,\n",
    "        color=\"red\",\n",
    "        s=3,\n",
    "        label=\"Russia Ukraine War chinease\" if index == 0 else \"\",\n",
    "    )\n",
    "plt.title(\n",
    "    f\"t-SNE visualization of document embeddings \\n {d} dimensions, {N} questions, {M} articles, {epo} epochs\"\n",
    ")\n",
    "\n",
    "plt.xlabel(\"t-SNE component 1\")\n",
    "plt.ylabel(\"t-SNE component 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
